Code Structure	"The code structures that comprise the product, from executables to individual routines."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Hardware Structure	Any hardware component that is integral to the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Non-executable Files	"Any files other than multimedia or programs, like text files, sample data, or help files."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Collateral	"Anything beyond software and hardware that is also part of the product, such as paper documents, web links and content, packaging, license agreements, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Application Functions	Any function that defines or distinguishes the product or fulfills core requirements.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Calculation Functions	Any arithmetic function or arithmetic operations embedded in other functions.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Time-related Functions	Time-out settings; daily or month-end reports; nightly batch jobs; time zones; business holidays; interest calculations; terms and warranty periods; chronograph functions.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Transformation Functions	"Functions that modify or transform something (e.g. setting fonts, inserting clip art, withdrawing money from account)."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Startup / Shutdown Functions	Each method and interface for invocation and initialization as well as exiting the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Multimedia Functions	"Sounds, bitmaps, videos, or any graphical display embedded in the product."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Error Handling Functions	"Any functions that detect and recover from errors, including all error messages."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Interaction Functions	Any interactions between functions within the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Testability Functions	"Any functions provided to help test the product, such as diagnostics, log files, asserts, test menus, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Input	Any data that is processed by the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Output	Any data that results from processing by the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Preset Data	"Any data that is supplied as part of the product, or otherwise built into it, such as prefabricated databases, default values, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Persistent Data	"Any data that is stored internally and expected to persist over multiple operations. This includes modes or states of the product, such as options settings, view modes, contents of documents, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Sequences/Combinations	"Any ordering or permutation of data, e.g. word order, sorted vs. unsorted data, order of tests."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Cardinality	"Numbers of objects or fields may vary (e.g. zero, one, many, max, open limit). Some may have to be unique (e.g. database keys)."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Size	Variations in the size and aggregation of data.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Noise	"Any data or state that is invalid, corrupted, or produced in an uncontrolled or incorrect fashion."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Data Lifecycle	"Transformations over the lifetime of a data entity as it is created, accessed, modified, and deleted."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
User Interfaces	"Any element that mediates the exchange of data with the user (e.g. displays, buttons, fields, whether physical or virtual)."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
System Interfaces	"Any interface with something other than a user, such as other programs, hard disk, network, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
API / SDK Interfaces	Any programmatic interfaces or tools intended to allow the development of new applications using this product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Import / Export Interfaces	"Any functions that package data for use by a different product, or interpret data from a different product."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
External Platform Hardware	"Hardware components and configurations that are not part of the shipping product, but are required (or optional) in order for the product to work: systems, servers, memory, keyboards, the Cloud."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
External Platform Software	"Software components and configurations that are not a part of the shipping product, but are required (or optional) in order for the product to work: operating systems, concurrently executing applications, drivers, fonts, etc."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Internal Platform Components	Libraries and other components that are embedded in your product but are produced outside your project.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Operational Environment	"The physical environment in which the product operates, including such elements as noise, light, and distractions."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Common Operational Use	Patterns and sequences of input that the product will typically encounter. This varies by user.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Disfavoured Operational Use	"Patterns of input produced by ignorant, mistaken, careless or malicious use."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Extreme Operational Use	Challenging patterns and sequences of input that are consistent with the intended use of the product.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Input / Output Timing	"When input is provided, when output created, and any timing relationships (delays, intervals, etc.) among them."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Fast / Slow Timing	Testing with 'fast' or 'slow' input; fastest and slowest; combinations of fast and slow.	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Changing Rates	"Speeding up and slowing down (spikes, bursts, hangs, bottlenecks, interruptions)."	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Concurrency	"More than one thing happening at once (multi-user, time-sharing, threads, and semaphores, shared data). "	SFDiPOT	James Bach	http://www.satisfice.com/tools/htsm.pdf	Test Strategy
Volume	How much space does the data take up?	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Velocity	"Velocity refers to the speed at which data is being generated, produced, created, or refreshed."	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Variety	"Structured / semistructured / unstructured data, different types: audio, image, video files, social media updates, and other text formats. Also log files, click data, machine and sensor data, etc."	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Variability	"Inconsistences in the data, mutiple data dimensions resulting from different types / sources, varying speed at which data is loaded."	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Veracity	"Relates to the reliability of the data, which is impacted by increases in the other properties."	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Validity	How accurate and correct the data is for its intended use?	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Vulnerability	"Is the data vulnerable at rest, in flight or during processing?"	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Volatility	"How old does your data need to be before it is considered irrelevant, historic, or not useful any longer? How long does data need to be kept for?"	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Visualisation	How challenging is the data to visualize?	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Value	How easy is it to derive value from the data?	VVVVVVVVVV	Various	https://upside.tdwi.org/articles/2017/02/08/10-vs-of-big-data.aspx	Test Data
Customers	"Who are the customers of the product? Not only those who use the software but also the people who are their customers, and the people who actually buy it."	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Information	"What are the sources of information about the product and the domain in which it will operate? Do testers already have background information; knowledge and inferences and implied specifications from which to derive test ideas? Do we have access to project planning documents, and if so, in what kind of shape are they? Who on the project could provide us with useful information?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Developer Relations	Who is responsible for the code? Where are they; in one location or all over the place? How do they get along with the rest of the project community? With each other?	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Test Team	"With whom are we working? Do we know yet? Is there a diversity of skills in place? Is someone going to have to do special research or training, or will we need to recruit outside help?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Equipment & Tools	"Is there a test lab set up, or do we have to make do with our own computers? Are there separate development, testing, and production environments available? Does our testing require peripherals or special hardware of some kind? Are our favorite testing tools available now, or are we going to have to collect and install them?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Schedule	"When can we expect code to test and documentation to read? What hard deadlines or milestones are in place? What is the rate of change on the project? How much time do we have for test planning, preparation, and execution? What do we have to do right now?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Test Items	"What is the product that we're testing? Do we have access to it? Is it relatively stable, or is it changing a lot? Will changes require new tests, or will we focus on retesting? What hooks or features exist that might make the product easier to test? And what is the future direction of the product?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Deliverables	"What do our clients want to see from the test process? How are we going to record and report progress? How formalized is the reporting process, and to whom do we report? Are there standards that we could - or must - follow?"	CIDTESTD	James Bach	http://www.developsense.com/articles/2005-09-StayingOnTheCriticalPath.pdf	Project Environment
Domain	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
User	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Function	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Flow	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Stress	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Scenario	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Claims	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Risk	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Automatic	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	DUFFSSCRA	James Bach		Test Technique
Capability	Can it perform the required functions?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Reliability	Will it work well and resist failure in all required situations?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Usability	How easy is it for a real user to use the product?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Security	How secure is it when it is deployed in the real world?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Scalability	How easily can it be scaled up / out to large numbers of users?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Performance	How speedy and responsive is it?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Installability	How easily can it be installed onto its target platform?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Compatability	How well does it work with external components & configurations?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Supportability	How economical will it be to provide support to users of the product?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Testability	How effectively can the product be tested?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Maintainability	"How economical will it be to build, fix or enhance the product?"	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Portability	How economical will it be to port or reuse the technology elsewhere?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
Localizability	How economical will it be to publish the product in another language?	CRUSSPIC STMPL	James Bach	http://www.satisfice.com/articles/hrbt.pdf	Quality Characteristic
History	We expect the present version of the system to be consistent with past versions of it.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Familiarity	We expect the system to be inconsistent with patterns of familiar problems.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Explainability	We expect a system to be understandable to the degree that we can articulately explain its behaviour to ourselves and others.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
World	We expect the product to be consistent with things that we know about or can observe in the world.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Image	"We expect the system to be consistent with an image that the organization wants to project, with its brand, or with its reputation."	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Comparable Products	"We expect the system to be consistent with systems that are in some way comparable. This includes other products in the same product line; competitive products, services, or systems; or products that are not in the same category but which process the same data; or alternative processes or algorithms."	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Claims	"We expect the system to be consistent with things important people say about it, whether in writing (references specifications, design documents, manuals, whiteboard sketches) or in conversation (meetings, public announcements, lunchroom conversations)."	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Users' Desires	We believe that the system should be consistent with ideas about what reasonable users might want.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Product	We expect each element of the system (or product) to be consistent with comparable elements in the same system.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Purpose	We expect the system to be consistent with the explicit and implicit uses to which people might put it.	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Statutes & Standards	"We expect a system to be consistent with relevant statutes, acts, laws, regulations, or standards."	FEW HICCUPPS	James Bach / Michael Bolton	http://www.developsense.com/blog/2012/07/few-hiccupps/	Test Oracle
Scouting Obsessively	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Authentic Problems	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Cognitive Savvy	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Knowledge Attracts Knowledge	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Experimentation	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Disposable Time	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Stories	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Other Minds	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Words & Pictures	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Systems Thinking	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	SACKED COWS	James Bach		Learning Heuristic
Past	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Results	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Obstacles	"What blockers or barriers did you encounter during the session? Did you overcome them, and how?"	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Outlook	"What's your outlook on the functionality you tested? Does it ""feel"" ready? Does it need further development?"	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Feelings	What feelings did you have during the session? How did they inform your testing?	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Learnings & Adaptation	What personal data did you gather during the session? What did you learn? How did your testing change as a result?	PROOFLA	"Jon Bach, Henrik Andersen"		Session Based Test Reporting
Modelling	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Resourcing	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Questioning	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Chartering	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Observing	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Manipulating	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Pairing	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Generating / Elaborating	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Refocusing	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Alternating	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Branching / Backtracking	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Conjecturing	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Recording	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Reporting	"Err, I couldn't find the original description for this Heuristic. You haven't seen it around, have you?"	MR.Q COMP GRABC R&R	Jon Bach		Exploration Skill / Tactic
Replicate It	Ideally the consumer of the bug report should be able to re-create the bug from the information contained in the report. 	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
Isolate It	Bug reports are more powerful and are generally taken more seriously when the steps to re-create the bug are simple. By isolating the actual bug -- separating it from any incidental or unrelated steps you took the first time you observed it -- frequently enables you to document the most direct (or at least a very direct) path to replicate the bug.	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
Maximise It	"We can't test everything, so we sample. When we observe a bug with our sampling, odds are that we didn't randomly stumble upon the most severe incarnation of the bug using whatever sampling method we employed. Try to recreate the bug by varying your test along various axes (data, configuration, navigation path, among others). Focus your report on the ""worst"" version of the failure you manage to create."	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
Generalize It	"Generalizing is the answer to ""No user we like would ever do that on purpose."" Demonstrating that a bug will be encountered by normal users performing normal activities will get more attention than demonstrating that an obscure bug may be encountered following an improbable path to accomplish a minimally important system function."	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
Externalize It	"Nobody cares if a bug annoys a tester. People care if a bug will annoy someone who pays to use the software, or writes reviews about the software, or who is likely to pay you for the work you did to develop the software in the first place. Focusing your bug reporting on the impact to people who matter makes your bug report more potent."	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
And Bland-ize It	"Say It Clearly and Dispassionately. Bug reports aren't personal. Neither are bugs. We are reporters, not accusers. "	RIMGEA	Cem Kaner	http://searchsoftwarequality.techtarget.com/tip/Software-testing-is-improved-by-good-bug-reporting	Bug Advocacy
Feature Tour	Move through the application and get familiar with all the controls and features you come across.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Complexity Tour	Find the five most complex things about the application	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Claims Tour	Find all the information in the product that tells you what the product does.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Configuration Tour	Attempt to find all the ways you can change settings in the product in a way that the application retains those settings.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
User Tour	Imagine five users for the product and the information they would want from the product or the major features they would be interested in.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Testability Tour	Find all the features you can use as testability features and/or identify tools you have available that you can use to help in your testing.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Scenario Tour	Imagine five realistic scenarios for how the users identified in the user tour would use this product.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Variability Tour	Look for things you can change in the application - and then you try to change them.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Interoperabilty Tour	What does this application interact with?	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Data Tour	Identify the major data elements of the application.	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Structure Tour	"Find everything you can about what comprises the physical product (code, interfaces, hardware, files, etc...)."	FCC CUTS VIDS	Michael D Kelly	http://michaeldkelly.com/blog/2005/9/20/touring-heuristic.html	Touring
Mission	"Be able to clarify what your current testing mission is; what you're testing, how you're testing it, what you're looking for."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Coverage	"Where am I looking? Be clear what areas of the application you're looking at, and what you're not looking at."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Obstacles	"What you've been unable to test, or things that have stopped you doing better testing."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Audience	"Understand who my audience is, what information they want, and what you think they need, and how the like to get it."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Status	"Describe how far through your testing you are, what you have and have not tested."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Techniques	What test techniques am I using?	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Environment	Where am I doing my testing?	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Risk	"What are the different risks I'm looking for, that I'm worried about, that I'm trying to uncover."	MCOASTER	Michael D Kelly	http://michaeldkelly.com/media/IWST_11.20.2010_TestingLightningTalks_MCOASTER_MichaelKelly.mp3	Test Reporting
Functional	Does the error detection and reporting function as required? Are errors not detected that should be detected? Are errors reported? Do error dialogs function as expected? Do the buttons work?	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
Appropriate	Are errors detected and reported in an accurate and timely manner for the intended audience? Are errors reported as soon as an error condition is met? Are warning messages displayed while there are enough resources to remedy the problem? Is a user allowed to waste time and effort only to be told that their work cannot be applied? Is the text of a message accurate? Does the text convey the situation to the intended audience? Is the error described in terms that will be understood by the intended audience?	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
Impact	Is the impact of the error sufficiently communicated to the user? Does the message contain too little information for the user to understand what occurred and how it impacts what they were attempting to do? Does the message contain extra information that distracts from communicating the impact?	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
Log	"Does technical information need to be logged for support, system administrators, developers, or testers? Will this log information be available if the user waits to contact support? Are log messages standardized to allow for automated information mining? Are logs detailed enough to facilitate troubleshooting? Are errors logged that add no value? Is there too much logging? Does excessive logging negatively impact performance and disk space? Does excessive logging complicate error investigation?"	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
UI	Are users given some indication that what they attempted to do failed? Are user interface messages worded for the intended audience? Are user interface error messages consistent with the look and feel of the software? Are error messages consistent with other activity that causes the same error elsewhere in the application? Are errors communicated in an efficient manner? Does a user need to click away excessive dialogs? Is this error best communicated as an error dialog? Is this error best communicated as text added to the window? Is this error best communicated audibly?	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
Recovery	"Does the error message tell the user how to recover from the error condition? Does the software facilitate recovery? If needed, is contact information provided? Is the user prompted through the recovery or left to figure it out on their own?"	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
Emotions	"What emotions are likely to be raised by the error message? Does the information in the message add to a user's frustration or help quiet it? If a user is being told that they need to pay more to use a feature, does the message encourage them to upgrade or does it encourage them to find a competitor's product? Does the error message cause more confusion?"	FAILURE	Ben Simo	http://www.questioningsoftware.com/2007/08/failure-usability.html	Error Handling
1. Security	"If there is a security problem, too it is often not an easy fix but means redesigning an entire section of code to be secure."	SLiME	Adam Goucher	http://adam.goucher.ca/?p=130	Order of Testing Tasks
2. Languages	"If there is a language problem, too it is often not an easy fix but means redesigning an entire section of code to support other languages that english (i18n, l10n)"	SLiME	Adam Goucher	http://adam.goucher.ca/?p=130	Order of Testing Tasks
3. RequIrements	"Test requirements, both implicit and explicit."	SLiME	Adam Goucher	http://adam.goucher.ca/?p=130	Order of Testing Tasks
4. Measurement	"Then move onto the types of tests that measure things, be it performance, stress or load testing."	SLiME	Adam Goucher	http://adam.goucher.ca/?p=130	Order of Testing Tasks
5. Existing	Look at existing functionality (regression test) as there should be no more changes to the underlying design of the code.	SLiME	Adam Goucher	http://adam.goucher.ca/?p=130	Order of Testing Tasks
Frequent	Common application usage.	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Intensive	Resource hogging activities.	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Business Critical	Even if these activities are both rare and not risky	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Legal	Stuff that will get you sued or not paid.	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Obvious	Stuff that is likely to earn you bad press	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Technically Risky	"New technologies, old technologies, places where itÆs failed before, previously under-tested areas"	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Stakeholder Mandated	Don't argue with the boss (too much).	FIBLOTS	Scott Barber	http://scott-barber.blogspot.co.uk/2011/09/model-workloads-for-performance-testing.html	Model Workloads for Performance Testing
Context	Project context is central to successful performance testing.	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Criteria	"Business, project, system, & user success criteria."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Design	"Identify system usage, and key metrics; plan and design tests."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Install	"Install and prepare environment, tools, & resource monitors."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Script	Implement test design using tools.	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Execute	"Run and monitor tests. Validate tests, test data, and results."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Analyze	Analyze the data individually and as a cross-functional team.	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Report	"Consolidate and share results, customized by audience."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
Iterate	" ""Lather, rinse, repeat"" as necessary."	CCD IS EARI	Scott Barber	http://scott-barber.blogspot.co.uk/2007/05/performance-testing-core-principles-ccd.html	Performance Testing Core Principle
